## CVE-2019-5435

### 0x00 Description

I found two integer overflow bugs in **libcurl/curl** (a well-known command line tool and library for transferring data with URLs) on HackerOne. The flaws can lead to a too small buffer allocation and a subsequent heap buffer overflow. CVE-2019-5435 was assgined for this issue.

### 0x01 How to find it

On the whole, I find it during my practice of code auditing. I analysed nearly all known prior vulnerabilities in cURL(https://curl.haxx.se/docs/security.html) and I see there are many integer overflow bugs caused by lacking check of the argument of function `malloc`. CVE-2018-14618 and CVE-2017-8816 are cases where a `strlen(str) * 2` happened. That may lead to a integer overflow on a 32bit OS when the `str` is longer than 2GB.

Fortunately, after regular search of  `malloc(xxx * n)`, I catched this issue.

### 0x02 Analysis

There is a potential integer overflow which may lead to a buffer overrun in /curl/lib/urlapi.c. In function `seturl`, urllen was multiplied by 2 and then passed to malloc. So an integer overflow will happen when the url is as long as 2GB in a 32 bit OS.

```c
static CURLUcode seturl(const char *url, CURLU *u, unsigned int flags)
{
  char *path;
  bool path_alloced = FALSE;
  char *hostname;
  char *query = NULL;
  char *fragment = NULL;
  CURLUcode result;
  bool url_has_scheme = FALSE;
  char schemebuf[MAX_SCHEME_LEN];
  char *schemep = NULL;
  size_t schemelen = 0;
  size_t urllen;
  const struct Curl_handler *h = NULL;

  if(!url)
    return CURLUE_MALFORMED_INPUT;

  /*************************************************************
   * Parse the URL.
   ************************************************************/
  /* allocate scratch area */
  urllen = strlen(url);
  path = u->scratch = malloc(urllen * 2 + 2); <= overflow here
```

The url was passed by `parseurl` to `seturl`.

```c
static CURLUcode parseurl(const char *url, CURLU *u, unsigned int flags)
{
  CURLUcode result = seturl(url, u, flags);
  if(result) {
    free_urlhandle(u);
    memset(u, 0, sizeof(struct Curl_URL));
  }
  return result;
}
```

And the `parseurl` was called when do `curl_url_set` and execute the parse of url. If someone use libcurl to code, and call `curl_url_set` with a extreme long url, it might be triggered.

```c
CURLUcode curl_url_set(CURLU *u, CURLUPart what,
                       const char *part, unsigned int flags)
......
case CURLUPART_URL: {
    /*
     * Allow a new URL to replace the existing (if any) contents.
     *
     * If the existing contents is enough for a URL, allow a relative URL to
     * replace it.
     */
    CURLUcode result;
    char *oldurl;
    char *redired_url;
    CURLU *handle2;

    if(Curl_is_absolute_url(part, NULL, MAX_SCHEME_LEN)) {
      handle2 = curl_url();
      if(!handle2)
        return CURLUE_OUT_OF_MEMORY;
      result = parseurl(part, handle2, flags); <= call parseurl
      if(!result)
        mv_urlhandle(handle2, u);
      else
        curl_url_cleanup(handle2);
      return result;
    }
```

Similarly, there is also a `nalloc * 3` issue in function `curl_url_set`.

```c
 if(storep) {
    const char *newp = part;
    size_t nalloc = strlen(part);

    if(nalloc > CURL_MAX_INPUT_LENGTH)
      /* excessive input length */
      return CURLUE_MALFORMED_INPUT;

    if(urlencode) {
      const unsigned char *i;
      char *o;
      bool free_part = FALSE;
      char *enc = malloc(nalloc * 3 + 1); /* for worst case! */
      if(!enc)
        return CURLUE_OUT_OF_MEMORY;
```

### 0x03 Reference

[security advisory](https://curl.haxx.se/docs/CVE-2019-5435.html)

[patch](https://github.com/curl/curl/commit/5fc28510a4664f4)